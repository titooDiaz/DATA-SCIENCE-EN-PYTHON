{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/CV/2_Convoluciones/ejercicios/ejercicios_solucion.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "metadata": {
        "id": "9ouKyK9RHrBg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "91186d53"
      },
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "## Mejorando LeNet\n",
        "\n",
        "Sabemos que LeNet fue un gran hito en su momento, pero también sabemos que hay modificaciones que podemos hacer a LeNet para mejorar su rendimiento.\n",
        "\n",
        "Apliquelas, usando de referencia el Pipeline usado en la clase teórica.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:15.531121Z",
          "iopub.status.busy": "2022-09-07T22:36:15.530759Z",
          "iopub.status.idle": "2022-09-07T22:36:17.530130Z",
          "shell.execute_reply": "2022-09-07T22:36:17.528931Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "6af9f4db"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:17.534765Z",
          "iopub.status.busy": "2022-09-07T22:36:17.534136Z",
          "iopub.status.idle": "2022-09-07T22:36:17.539915Z",
          "shell.execute_reply": "2022-09-07T22:36:17.538823Z"
        },
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "500f8d90"
      },
      "outputs": [],
      "source": [
        "def init_cnn(module):\n",
        "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
        "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(module.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:17.543613Z",
          "iopub.status.busy": "2022-09-07T22:36:17.543143Z",
          "iopub.status.idle": "2022-09-07T22:36:17.549868Z",
          "shell.execute_reply": "2022-09-07T22:36:17.549016Z"
        },
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "id": "b845b46b"
      },
      "outputs": [],
      "source": [
        "NUM_CHANNEL1 = 6\n",
        "NUM_CHANNEL2 = 16\n",
        "NUM_MLP1 = 120\n",
        "NUM_MLP2 = 84\n",
        "num_classes = 10\n",
        "\n",
        "## Defina aquí su modelo.\n",
        "model = nn.Sequential(\n",
        "            nn.LazyConv2d(NUM_CHANNEL1, kernel_size=5, padding=2), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(NUM_CHANNEL2, kernel_size=5), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(NUM_MLP1), nn.ReLU(),\n",
        "            nn.LazyLinear(NUM_MLP2), nn.ReLU(),\n",
        "            nn.LazyLinear(num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:17.553576Z",
          "iopub.status.busy": "2022-09-07T22:36:17.553152Z",
          "iopub.status.idle": "2022-09-07T22:36:17.596538Z",
          "shell.execute_reply": "2022-09-07T22:36:17.595333Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "c0d44c17",
        "outputId": "165ba9cb-0c0f-4360-bf5f-839f0daa6aeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada original:\t torch.Size([1, 1, 28, 28])\n",
            "Salida tras Conv2d:\t torch.Size([1, 6, 28, 28])\n",
            "Salida tras ReLU:\t torch.Size([1, 6, 28, 28])\n",
            "Salida tras MaxPool2d:\t torch.Size([1, 6, 14, 14])\n",
            "Salida tras Conv2d:\t torch.Size([1, 16, 10, 10])\n",
            "Salida tras ReLU:\t torch.Size([1, 16, 10, 10])\n",
            "Salida tras MaxPool2d:\t torch.Size([1, 16, 5, 5])\n",
            "Salida tras Flatten:\t torch.Size([1, 400])\n",
            "Salida tras Linear:\t torch.Size([1, 120])\n",
            "Salida tras ReLU:\t torch.Size([1, 120])\n",
            "Salida tras Linear:\t torch.Size([1, 84])\n",
            "Salida tras ReLU:\t torch.Size([1, 84])\n",
            "Salida tras Linear:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "def layer_summary(net, X_shape):\n",
        "    X = torch.randn(*X_shape)\n",
        "    print(\"Entrada original:\\t\", X.shape)\n",
        "    for layer in net:\n",
        "        X = layer(X)\n",
        "        print(\"Salida tras \"+layer.__class__.__name__+':\\t', X.shape)\n",
        "\n",
        "layer_summary(model, (1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 10,
        "id": "56cc32df"
      },
      "source": [
        "## Cargando los datos.\n",
        "\n",
        "Como dijimos, vamos a trabajar con Fashion MNIST. Para ello cargaremos le dataset desde la biblioteca de torch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "\n",
        "def load_data_fashion_mnist(batch_size):\n",
        "    trans = [transforms.ToTensor()]\n",
        "    trans = transforms.Compose(trans)\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(\n",
        "        root=\"../data\", train=True, transform=trans, download=True)\n",
        "    length = len(mnist_train)\n",
        "    stop = int(len(mnist_train) * 0.7)\n",
        "    mnist_val = [mnist_train[i] for i in range(stop,length)]\n",
        "    mnist_train = [mnist_train[i] for i in range(stop)]\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(\n",
        "        root=\"../data\", train=False, transform=trans, download=True)\n",
        "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                            num_workers=1),\n",
        "            data.DataLoader(mnist_val, batch_size, shuffle=True,\n",
        "                            num_workers=1),\n",
        "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                            num_workers=1))\n",
        "\n",
        "batch_size = 1024\n",
        "iter_train, iter_val, iter_test = load_data_fashion_mnist(batch_size)\n"
      ],
      "metadata": {
        "id": "e_RXGdi4ttbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También calcularemos el accuracy de nuestro modelo."
      ],
      "metadata": {
        "id": "RHQAvElBnG0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "\n",
        "    # aproximamos al entero más cercano\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    correct = (preds == y).float() #convertimos a flotante para la división\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "55lh8pUWwrGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiremos una función de entrenamiento y evaluación como las que habíamos usado antes."
      ],
      "metadata": {
        "id": "m3x5g4YJnUrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "        image, label = batch\n",
        "        image, label  = image.to(device), label.to(device)      \n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        acc = binary_accuracy(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "Z-lJWjrusi6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for batch in iterator:\n",
        "\n",
        "          image, label = batch\n",
        "          image, label  = image.to(device), label.to(device)      \n",
        "          optimizer.zero_grad()\n",
        "          output = model(image)\n",
        "          loss = criterion(output, label)\n",
        "          acc = binary_accuracy(output, label)\n",
        "          epoch_loss += loss.item()\n",
        "          epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "JxH4-DPyxOW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y una función para calcular el tiempo de cálculo"
      ],
      "metadata": {
        "id": "0oJBb5OIn7pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "5BNJAZKbxyTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento"
      ],
      "metadata": {
        "id": "yoI6skXundge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "0_u0iI3Cx4Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, iter_train, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, iter_val, criterion, device)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train acc.: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. acc.: {valid_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrXqxmgiyBeE",
        "outputId": "05c126b4-97e5-4d70-f0e8-e344bf369fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 1s\n",
            "\tTrain Loss: 1.804 | Train acc.: 0.411\n",
            "\t Val. Loss: 0.981 |  Val. acc.: 0.611\n",
            "Epoch: 02 | Time: 0m 0s\n",
            "\tTrain Loss: 0.796 | Train acc.: 0.700\n",
            "\t Val. Loss: 0.723 |  Val. acc.: 0.715\n",
            "Epoch: 03 | Time: 0m 0s\n",
            "\tTrain Loss: 0.687 | Train acc.: 0.733\n",
            "\t Val. Loss: 0.639 |  Val. acc.: 0.755\n",
            "Epoch: 04 | Time: 0m 0s\n",
            "\tTrain Loss: 0.612 | Train acc.: 0.761\n",
            "\t Val. Loss: 0.598 |  Val. acc.: 0.767\n",
            "Epoch: 05 | Time: 0m 0s\n",
            "\tTrain Loss: 0.563 | Train acc.: 0.782\n",
            "\t Val. Loss: 0.558 |  Val. acc.: 0.790\n",
            "Epoch: 06 | Time: 0m 0s\n",
            "\tTrain Loss: 0.529 | Train acc.: 0.798\n",
            "\t Val. Loss: 0.535 |  Val. acc.: 0.800\n",
            "Epoch: 07 | Time: 0m 0s\n",
            "\tTrain Loss: 0.508 | Train acc.: 0.812\n",
            "\t Val. Loss: 0.510 |  Val. acc.: 0.812\n",
            "Epoch: 08 | Time: 0m 0s\n",
            "\tTrain Loss: 0.491 | Train acc.: 0.818\n",
            "\t Val. Loss: 0.544 |  Val. acc.: 0.781\n",
            "Epoch: 09 | Time: 0m 0s\n",
            "\tTrain Loss: 0.482 | Train acc.: 0.821\n",
            "\t Val. Loss: 0.519 |  Val. acc.: 0.789\n",
            "Epoch: 10 | Time: 0m 0s\n",
            "\tTrain Loss: 0.460 | Train acc.: 0.833\n",
            "\t Val. Loss: 0.472 |  Val. acc.: 0.828\n",
            "Epoch: 11 | Time: 0m 0s\n",
            "\tTrain Loss: 0.439 | Train acc.: 0.842\n",
            "\t Val. Loss: 0.456 |  Val. acc.: 0.831\n",
            "Epoch: 12 | Time: 0m 0s\n",
            "\tTrain Loss: 0.429 | Train acc.: 0.845\n",
            "\t Val. Loss: 0.464 |  Val. acc.: 0.835\n",
            "Epoch: 13 | Time: 0m 0s\n",
            "\tTrain Loss: 0.427 | Train acc.: 0.848\n",
            "\t Val. Loss: 0.426 |  Val. acc.: 0.846\n",
            "Epoch: 14 | Time: 0m 0s\n",
            "\tTrain Loss: 0.399 | Train acc.: 0.857\n",
            "\t Val. Loss: 0.415 |  Val. acc.: 0.850\n",
            "Epoch: 15 | Time: 0m 0s\n",
            "\tTrain Loss: 0.391 | Train acc.: 0.862\n",
            "\t Val. Loss: 0.417 |  Val. acc.: 0.852\n",
            "Epoch: 16 | Time: 0m 0s\n",
            "\tTrain Loss: 0.386 | Train acc.: 0.865\n",
            "\t Val. Loss: 0.406 |  Val. acc.: 0.853\n",
            "Epoch: 17 | Time: 0m 0s\n",
            "\tTrain Loss: 0.365 | Train acc.: 0.870\n",
            "\t Val. Loss: 0.383 |  Val. acc.: 0.864\n",
            "Epoch: 18 | Time: 0m 0s\n",
            "\tTrain Loss: 0.366 | Train acc.: 0.868\n",
            "\t Val. Loss: 0.389 |  Val. acc.: 0.861\n",
            "Epoch: 19 | Time: 0m 0s\n",
            "\tTrain Loss: 0.380 | Train acc.: 0.869\n",
            "\t Val. Loss: 0.439 |  Val. acc.: 0.838\n",
            "Epoch: 20 | Time: 0m 0s\n",
            "\tTrain Loss: 0.393 | Train acc.: 0.860\n",
            "\t Val. Loss: 0.528 |  Val. acc.: 0.812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, iter_test, criterion ,device)\n",
        "\n",
        "print(f'\\t Test. acc: {test_loss:.3f} |  test. acc: {test_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a-3dNLjyRtl",
        "outputId": "394a410d-3dd5-4ec1-859f-484f9c9bfe73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Test. acc: 0.393 |  test. acc: 0.860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 1,
        "id": "dr56eZKbv7Sp"
      },
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "## Cambiando el dataset.\n",
        "\n",
        "Dado los resultados que tenemos con Fashion MNIST, es una buena idea tratar de probar otro dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:15.531121Z",
          "iopub.status.busy": "2022-09-07T22:36:15.530759Z",
          "iopub.status.idle": "2022-09-07T22:36:17.530130Z",
          "shell.execute_reply": "2022-09-07T22:36:17.528931Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "33EQY_aAv7Sr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:17.534765Z",
          "iopub.status.busy": "2022-09-07T22:36:17.534136Z",
          "iopub.status.idle": "2022-09-07T22:36:17.539915Z",
          "shell.execute_reply": "2022-09-07T22:36:17.538823Z"
        },
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "QkjFUZMCv7St"
      },
      "outputs": [],
      "source": [
        "def init_cnn(module):\n",
        "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
        "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(module.weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vamos a trabajar con imágenes en colores (3 canales RGB rojo, verde y azul), lo primero que haremos será aumentar el número de canales. Además, dado que CIFAR10 tiene imágenes de $32×32$ eliminaremos el padding de la primera capa convolucional para obtener mapas receptivos similares a los de FashionMNIST. Tambien cambiaremos el número de salidas de la primera capa densa"
      ],
      "metadata": {
        "id": "MNur3Dibyucr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:17.543613Z",
          "iopub.status.busy": "2022-09-07T22:36:17.543143Z",
          "iopub.status.idle": "2022-09-07T22:36:17.549868Z",
          "shell.execute_reply": "2022-09-07T22:36:17.549016Z"
        },
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ],
        "id": "ge8e17vzv7Su"
      },
      "outputs": [],
      "source": [
        "NUM_CHANNEL1 = 20\n",
        "NUM_CHANNEL2 = 50\n",
        "NUM_MLP1 = 200\n",
        "NUM_MLP2 = 80\n",
        "num_classes = 10\n",
        "\n",
        "## Defina aquí su modelo.\n",
        "model = nn.Sequential(\n",
        "            nn.LazyConv2d(NUM_CHANNEL1, kernel_size=5), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(NUM_CHANNEL2, kernel_size=5), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(NUM_MLP1), nn.ReLU(),\n",
        "            nn.LazyLinear(NUM_MLP2), nn.ReLU(),\n",
        "            nn.LazyLinear(num_classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-07T22:36:17.553576Z",
          "iopub.status.busy": "2022-09-07T22:36:17.553152Z",
          "iopub.status.idle": "2022-09-07T22:36:17.596538Z",
          "shell.execute_reply": "2022-09-07T22:36:17.595333Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "outputId": "491d9e3d-6973-48b1-b1bf-0ad3710c1209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL_1lKXyv7Sv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada original:\t torch.Size([1, 3, 32, 32])\n",
            "Salida tras Conv2d:\t torch.Size([1, 20, 28, 28])\n",
            "Salida tras ReLU:\t torch.Size([1, 20, 28, 28])\n",
            "Salida tras MaxPool2d:\t torch.Size([1, 20, 14, 14])\n",
            "Salida tras Conv2d:\t torch.Size([1, 50, 10, 10])\n",
            "Salida tras ReLU:\t torch.Size([1, 50, 10, 10])\n",
            "Salida tras MaxPool2d:\t torch.Size([1, 50, 5, 5])\n",
            "Salida tras Flatten:\t torch.Size([1, 1250])\n",
            "Salida tras Linear:\t torch.Size([1, 200])\n",
            "Salida tras ReLU:\t torch.Size([1, 200])\n",
            "Salida tras Linear:\t torch.Size([1, 80])\n",
            "Salida tras ReLU:\t torch.Size([1, 80])\n",
            "Salida tras Linear:\t torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "def layer_summary(net, X_shape):\n",
        "    X = torch.randn(*X_shape)\n",
        "    print(\"Entrada original:\\t\", X.shape)\n",
        "    for layer in net:\n",
        "        X = layer(X)\n",
        "        print(\"Salida tras \"+layer.__class__.__name__+':\\t', X.shape)\n",
        "\n",
        "layer_summary(model, (1, 3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio 3"
      ],
      "metadata": {
        "id": "VqWGU6mxdHnC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 10,
        "id": "7Ew-6QqRv7Sw"
      },
      "source": [
        "\n",
        "\n",
        "## Cargando los datos.\n",
        "\n",
        "Ahora trabajaremos con CIFAR10 un dataset que tiene imagenes de en colores de $32\\times32$. Defina una función que genere iteradores de entrenamiento, validación y prueba para este dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "\n",
        "def load_data_fashion_mnist(batch_size):\n",
        "  ## inserte aquí su código\n",
        "    trans = [transforms.ToTensor()]\n",
        "    trans = transforms.Compose(trans)\n",
        "    mnist_train = torchvision.datasets.CIFAR10(\n",
        "        root=\"../data\", train=True, transform=trans, download=True)\n",
        "    length = len(mnist_train)\n",
        "    stop = int(len(mnist_train) * 0.7)\n",
        "    mnist_val = [mnist_train[i] for i in range(stop,length)]\n",
        "    mnist_train = [mnist_train[i] for i in range(stop)]\n",
        "    mnist_test = torchvision.datasets.CIFAR10(\n",
        "        root=\"../data\", train=False, transform=trans, download=True)\n",
        "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                            num_workers=1),\n",
        "            data.DataLoader(mnist_val, batch_size, shuffle=True,\n",
        "                            num_workers=1),\n",
        "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                            num_workers=1))\n",
        "\n",
        "batch_size = 1024\n",
        "iter_train, iter_val, iter_test = load_data_fashion_mnist(batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9805ec20-0bf7-4a5b-aebe-95f509aee800",
        "id": "bPcW9pfWv7Sx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También calcularemos el accuracy de nuestro modelo."
      ],
      "metadata": {
        "id": "lpf7fMSVv7Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "\n",
        "    # aproximamos al entero más cercano\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    correct = (preds == y).float() #convertimos a flotante para la división\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "d8bXGKPjv7S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiremos una función de entrenamiento y evaluación como las que habíamos usado antes."
      ],
      "metadata": {
        "id": "VXLxaqO1v7S0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "        image, label = batch\n",
        "        image, label  = image.to(device), label.to(device)      \n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        acc = binary_accuracy(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "QZQu_hEUv7S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    epoch_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for batch in iterator:\n",
        "\n",
        "          image, label = batch\n",
        "          image, label  = image.to(device), label.to(device)      \n",
        "          optimizer.zero_grad()\n",
        "          output = model(image)\n",
        "          loss = criterion(output, label)\n",
        "          acc = binary_accuracy(output, label)\n",
        "          epoch_loss += loss.item()\n",
        "          epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "VkzJYuF2v7S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y una función para calcular el tiempo de cálculo"
      ],
      "metadata": {
        "id": "G2niILlxv7S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "NmTihLBXv7S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento"
      ],
      "metadata": {
        "id": "tiGlABSyv7S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "IMbsjmrmv7S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "N_EPOCHS = 50\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, iter_train, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, iter_val, criterion, device)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train acc.: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. acc.: {valid_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e19b19-02c1-4338-9e9c-78101eb4b764",
        "id": "f_ngmFH0v7S7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 1s\n",
            "\tTrain Loss: 2.062 | Train acc.: 0.230\n",
            "\t Val. Loss: 1.851 |  Val. acc.: 0.321\n",
            "Epoch: 02 | Time: 0m 1s\n",
            "\tTrain Loss: 1.757 | Train acc.: 0.364\n",
            "\t Val. Loss: 1.701 |  Val. acc.: 0.373\n",
            "Epoch: 03 | Time: 0m 1s\n",
            "\tTrain Loss: 1.639 | Train acc.: 0.403\n",
            "\t Val. Loss: 1.620 |  Val. acc.: 0.409\n",
            "Epoch: 04 | Time: 0m 1s\n",
            "\tTrain Loss: 1.560 | Train acc.: 0.432\n",
            "\t Val. Loss: 1.526 |  Val. acc.: 0.445\n",
            "Epoch: 05 | Time: 0m 1s\n",
            "\tTrain Loss: 1.501 | Train acc.: 0.453\n",
            "\t Val. Loss: 1.516 |  Val. acc.: 0.452\n",
            "Epoch: 06 | Time: 0m 1s\n",
            "\tTrain Loss: 1.440 | Train acc.: 0.480\n",
            "\t Val. Loss: 1.464 |  Val. acc.: 0.477\n",
            "Epoch: 07 | Time: 0m 1s\n",
            "\tTrain Loss: 1.401 | Train acc.: 0.494\n",
            "\t Val. Loss: 1.417 |  Val. acc.: 0.488\n",
            "Epoch: 08 | Time: 0m 1s\n",
            "\tTrain Loss: 1.373 | Train acc.: 0.504\n",
            "\t Val. Loss: 1.371 |  Val. acc.: 0.508\n",
            "Epoch: 09 | Time: 0m 1s\n",
            "\tTrain Loss: 1.385 | Train acc.: 0.505\n",
            "\t Val. Loss: 1.355 |  Val. acc.: 0.511\n",
            "Epoch: 10 | Time: 0m 1s\n",
            "\tTrain Loss: 1.300 | Train acc.: 0.535\n",
            "\t Val. Loss: 1.368 |  Val. acc.: 0.511\n",
            "Epoch: 11 | Time: 0m 1s\n",
            "\tTrain Loss: 1.280 | Train acc.: 0.541\n",
            "\t Val. Loss: 1.297 |  Val. acc.: 0.530\n",
            "Epoch: 12 | Time: 0m 1s\n",
            "\tTrain Loss: 1.243 | Train acc.: 0.553\n",
            "\t Val. Loss: 1.248 |  Val. acc.: 0.557\n",
            "Epoch: 13 | Time: 0m 1s\n",
            "\tTrain Loss: 1.217 | Train acc.: 0.569\n",
            "\t Val. Loss: 1.274 |  Val. acc.: 0.551\n",
            "Epoch: 14 | Time: 0m 1s\n",
            "\tTrain Loss: 1.195 | Train acc.: 0.577\n",
            "\t Val. Loss: 1.299 |  Val. acc.: 0.536\n",
            "Epoch: 15 | Time: 0m 1s\n",
            "\tTrain Loss: 1.179 | Train acc.: 0.581\n",
            "\t Val. Loss: 1.284 |  Val. acc.: 0.539\n",
            "Epoch: 16 | Time: 0m 1s\n",
            "\tTrain Loss: 1.169 | Train acc.: 0.582\n",
            "\t Val. Loss: 1.223 |  Val. acc.: 0.570\n",
            "Epoch: 17 | Time: 0m 1s\n",
            "\tTrain Loss: 1.130 | Train acc.: 0.602\n",
            "\t Val. Loss: 1.226 |  Val. acc.: 0.568\n",
            "Epoch: 18 | Time: 0m 1s\n",
            "\tTrain Loss: 1.114 | Train acc.: 0.608\n",
            "\t Val. Loss: 1.166 |  Val. acc.: 0.590\n",
            "Epoch: 19 | Time: 0m 1s\n",
            "\tTrain Loss: 1.081 | Train acc.: 0.618\n",
            "\t Val. Loss: 1.162 |  Val. acc.: 0.594\n",
            "Epoch: 20 | Time: 0m 1s\n",
            "\tTrain Loss: 1.058 | Train acc.: 0.628\n",
            "\t Val. Loss: 1.132 |  Val. acc.: 0.604\n",
            "Epoch: 21 | Time: 0m 1s\n",
            "\tTrain Loss: 1.051 | Train acc.: 0.631\n",
            "\t Val. Loss: 1.124 |  Val. acc.: 0.606\n",
            "Epoch: 22 | Time: 0m 1s\n",
            "\tTrain Loss: 1.023 | Train acc.: 0.640\n",
            "\t Val. Loss: 1.099 |  Val. acc.: 0.617\n",
            "Epoch: 23 | Time: 0m 1s\n",
            "\tTrain Loss: 1.014 | Train acc.: 0.645\n",
            "\t Val. Loss: 1.108 |  Val. acc.: 0.611\n",
            "Epoch: 24 | Time: 0m 1s\n",
            "\tTrain Loss: 0.995 | Train acc.: 0.651\n",
            "\t Val. Loss: 1.087 |  Val. acc.: 0.622\n",
            "Epoch: 25 | Time: 0m 1s\n",
            "\tTrain Loss: 0.995 | Train acc.: 0.652\n",
            "\t Val. Loss: 1.140 |  Val. acc.: 0.597\n",
            "Epoch: 26 | Time: 0m 1s\n",
            "\tTrain Loss: 0.986 | Train acc.: 0.653\n",
            "\t Val. Loss: 1.073 |  Val. acc.: 0.627\n",
            "Epoch: 27 | Time: 0m 1s\n",
            "\tTrain Loss: 0.965 | Train acc.: 0.660\n",
            "\t Val. Loss: 1.079 |  Val. acc.: 0.624\n",
            "Epoch: 28 | Time: 0m 1s\n",
            "\tTrain Loss: 0.946 | Train acc.: 0.667\n",
            "\t Val. Loss: 1.057 |  Val. acc.: 0.635\n",
            "Epoch: 29 | Time: 0m 1s\n",
            "\tTrain Loss: 0.933 | Train acc.: 0.674\n",
            "\t Val. Loss: 1.070 |  Val. acc.: 0.627\n",
            "Epoch: 30 | Time: 0m 1s\n",
            "\tTrain Loss: 0.925 | Train acc.: 0.675\n",
            "\t Val. Loss: 1.038 |  Val. acc.: 0.640\n",
            "Epoch: 31 | Time: 0m 1s\n",
            "\tTrain Loss: 0.906 | Train acc.: 0.684\n",
            "\t Val. Loss: 1.029 |  Val. acc.: 0.643\n",
            "Epoch: 32 | Time: 0m 1s\n",
            "\tTrain Loss: 0.888 | Train acc.: 0.688\n",
            "\t Val. Loss: 1.082 |  Val. acc.: 0.622\n",
            "Epoch: 33 | Time: 0m 1s\n",
            "\tTrain Loss: 0.878 | Train acc.: 0.690\n",
            "\t Val. Loss: 1.049 |  Val. acc.: 0.635\n",
            "Epoch: 34 | Time: 0m 1s\n",
            "\tTrain Loss: 0.874 | Train acc.: 0.692\n",
            "\t Val. Loss: 1.033 |  Val. acc.: 0.642\n",
            "Epoch: 35 | Time: 0m 1s\n",
            "\tTrain Loss: 0.847 | Train acc.: 0.702\n",
            "\t Val. Loss: 1.065 |  Val. acc.: 0.633\n",
            "Epoch: 36 | Time: 0m 1s\n",
            "\tTrain Loss: 0.844 | Train acc.: 0.707\n",
            "\t Val. Loss: 1.045 |  Val. acc.: 0.640\n",
            "Epoch: 37 | Time: 0m 1s\n",
            "\tTrain Loss: 0.817 | Train acc.: 0.711\n",
            "\t Val. Loss: 1.018 |  Val. acc.: 0.649\n",
            "Epoch: 38 | Time: 0m 1s\n",
            "\tTrain Loss: 0.811 | Train acc.: 0.717\n",
            "\t Val. Loss: 1.038 |  Val. acc.: 0.641\n",
            "Epoch: 39 | Time: 0m 1s\n",
            "\tTrain Loss: 0.810 | Train acc.: 0.716\n",
            "\t Val. Loss: 0.986 |  Val. acc.: 0.663\n",
            "Epoch: 40 | Time: 0m 1s\n",
            "\tTrain Loss: 0.791 | Train acc.: 0.722\n",
            "\t Val. Loss: 1.093 |  Val. acc.: 0.623\n",
            "Epoch: 41 | Time: 0m 1s\n",
            "\tTrain Loss: 0.808 | Train acc.: 0.715\n",
            "\t Val. Loss: 1.134 |  Val. acc.: 0.617\n",
            "Epoch: 42 | Time: 0m 1s\n",
            "\tTrain Loss: 0.792 | Train acc.: 0.724\n",
            "\t Val. Loss: 0.998 |  Val. acc.: 0.659\n",
            "Epoch: 43 | Time: 0m 1s\n",
            "\tTrain Loss: 0.767 | Train acc.: 0.733\n",
            "\t Val. Loss: 1.026 |  Val. acc.: 0.647\n",
            "Epoch: 44 | Time: 0m 1s\n",
            "\tTrain Loss: 0.751 | Train acc.: 0.737\n",
            "\t Val. Loss: 0.992 |  Val. acc.: 0.659\n",
            "Epoch: 45 | Time: 0m 1s\n",
            "\tTrain Loss: 0.735 | Train acc.: 0.743\n",
            "\t Val. Loss: 1.024 |  Val. acc.: 0.654\n",
            "Epoch: 46 | Time: 0m 1s\n",
            "\tTrain Loss: 0.725 | Train acc.: 0.746\n",
            "\t Val. Loss: 0.993 |  Val. acc.: 0.660\n",
            "Epoch: 47 | Time: 0m 1s\n",
            "\tTrain Loss: 0.717 | Train acc.: 0.748\n",
            "\t Val. Loss: 1.024 |  Val. acc.: 0.653\n",
            "Epoch: 48 | Time: 0m 1s\n",
            "\tTrain Loss: 0.703 | Train acc.: 0.755\n",
            "\t Val. Loss: 1.009 |  Val. acc.: 0.659\n",
            "Epoch: 49 | Time: 0m 1s\n",
            "\tTrain Loss: 0.694 | Train acc.: 0.757\n",
            "\t Val. Loss: 0.998 |  Val. acc.: 0.665\n",
            "Epoch: 50 | Time: 0m 1s\n",
            "\tTrain Loss: 0.673 | Train acc.: 0.766\n",
            "\t Val. Loss: 1.045 |  Val. acc.: 0.654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, iter_test, criterion ,device)\n",
        "\n",
        "print(f'\\t Test. loss: {test_loss:.3f} |  test. acc: {test_acc:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8931bc5-9b33-4a29-fe9b-4031639634c7",
        "id": "NtifVY--v7S7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Test. acc: 0.986 |  test. acc: 0.661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio 4\n",
        "\n",
        "\n",
        "#Formas, Tamaños y Salidas"
      ],
      "metadata": {
        "id": "hnLd57PZdXe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los siguientes ejercicios están hechos para practicar, entender y aprender como cambian los tamaños de las salidas y entradas al aplicar padding y strides"
      ],
      "metadata": {
        "id": "v9iZFbdSeFfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "eVSUJuK_e-Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Defina un tensor de $15 \\times 15$ y aplique una convolución con kernel $5 \\times 5$ de tal manera que a la salida tenga un solo mapa de características de $3 \\times 3$. No debe utilizar padding\n",
        "> NOTA: Recuerde que las convoluciones espera a la entrada tensores de la forma:\n",
        "`X = [tamaño de minilote, numero de canales, alto en píxeles, ancho en píxeles]`"
      ],
      "metadata": {
        "id": "sWee9-I8er-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserte su código\n",
        "\n",
        "X1 = torch.randn((1,1,15,15))\n",
        "net1 = nn.Sequential(nn.LazyConv2d(1, kernel_size=5, stride=5))\n",
        "Y1 = net1(X1)\n",
        "print(Y1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaTFsFM_eYu4",
        "outputId": "5010be4d-d4d8-4c9e-b7f0-2b6725743b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 3, 3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Defina un tensor de $7 \\times 7$ y aplique una convolución con kernel $3 \\times 3$ de tal manera que a la salida tenga un solo mapa de características de $3 \\times 3$."
      ],
      "metadata": {
        "id": "5vIlNC1EgxW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserte su código\n",
        "\n",
        "X1 = torch.randn((1,1,7,7))\n",
        "net1 = nn.Sequential(nn.LazyConv2d(1, kernel_size=3, stride=3, padding=1))\n",
        "Y1 = net1(X1)\n",
        "print(Y1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_I5EYZZf-qN",
        "outputId": "e4f75882-ac02-452a-d464-18ee7ef16a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Dado un mapa de carácteristicas de la forma $100 \\times 100$ y una convolución con kernel $7 \\times 7$. ¿Cual era el tamaño original de la imagen de entrada?"
      ],
      "metadata": {
        "id": "6FF-xKqXh8FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserte su código\n",
        "\n",
        "X1 = torch.randn((1,1,106,106))\n",
        "net1 = nn.Sequential(nn.LazyConv2d(1, kernel_size=7))\n",
        "Y1 = net1(X1)\n",
        "print(Y1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC2ifmpaiP0g",
        "outputId": "4be8e1d8-6f08-4ace-dd73-7e67b71816c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 100, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Para una imagen de $16\\times16$, al aplicar una ventana de pooling de $2\\times2$, ¿Cual es el tamaño esperado a la salida?"
      ],
      "metadata": {
        "id": "uCOwZpytib8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserte su código\n",
        "\n",
        "X1 = torch.randn((1,1,16,16))\n",
        "net1 = nn.Sequential(nn.MaxPool2d(kernel_size=2))\n",
        "Y1 = net1(X1)\n",
        "print(Y1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A6dZ4syisu4",
        "outputId": "4c2c1626-8b3e-4903-9789-c7a3c1f9e217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Para una imagen de $16\\times16$, si aplicamos una ventana de pooling de $2\\times2$, ¿Podemos obtener un salida de $4\\times4$ usando strides?"
      ],
      "metadata": {
        "id": "8eeFGLdoi9SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inserte su código\n",
        "\n",
        "X1 = torch.randn((1,1,16,16))\n",
        "net1 = nn.Sequential(nn.MaxPool2d(kernel_size=2,stride=4))\n",
        "Y1 = net1(X1)\n",
        "print(Y1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZNxHQSIjTHr",
        "outputId": "b728c93e-3e8d-408c-da6d-6d87e297a85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ejercicio 5\n",
        "\n",
        "Entrenando kernels preexistentes\n",
        "\n",
        "En la clase presentamos un pequeño pipeline para mostrar como entrenar un kernel. Nuestra intención en este ejercicio es replicar eso resultados para los siguientes ejemplos:"
      ],
      "metadata": {
        "id": "hflokgO2jsKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operador Laplaciano"
      ],
      "metadata": {
        "id": "hfeLsxXXsYj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.Tensor.uniform_(torch.Tensor(1,1,64,64))\n",
        "K = torch.Tensor([  [0,  1, 0],\n",
        "                    [1, -4, 1],\n",
        "                    [0,  1, 0], ])\n",
        "\n",
        "def corr2d(X, K): \n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[-2] - h + 1, X.shape[-1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[0][0][i:i + h, j:j + w] * K).sum() # producto de Haddamar\n",
        "    return Y\n",
        "\n",
        "Y = corr2d(X,K)\n",
        "\n",
        "# inserte su codigo.\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=3, bias=False)\n",
        "\n",
        "lr = 3e-1  # Learning rate\n",
        "\n",
        "for i in range(100):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y) ** 2 ## minimos cuadrados\n",
        "    conv2d.zero_grad()\n",
        "    l.mean().backward()\n",
        "    # actualizamos los pesos\n",
        "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f'epoch {i + 1}, loss {l.sum():.3f}')\n",
        "\n",
        "print(conv2d.weight.data)\n",
        "print(K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp89LeA8pLn3",
        "outputId": "3591b4b5-c893-4d63-9f49-ebac2e43c042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20, loss 918.581\n",
            "epoch 40, loss 121.710\n",
            "epoch 60, loss 16.184\n",
            "epoch 80, loss 2.160\n",
            "epoch 100, loss 0.289\n",
            "tensor([[[[ 8.4668e-04,  9.9256e-01, -1.0056e-03],\n",
            "          [ 9.9378e-01, -3.9745e+00,  9.9316e-01],\n",
            "          [-3.8226e-04,  9.9379e-01,  1.7304e-03]]]])\n",
            "tensor([[ 0.,  1.,  0.],\n",
            "        [ 1., -4.,  1.],\n",
            "        [ 0.,  1.,  0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suavizador Gaussiano"
      ],
      "metadata": {
        "id": "KxbKd8YJs1_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.Tensor.uniform_(torch.Tensor(1,1,64,64))\n",
        "K = torch.Tensor([  [1.0, 2.0, 1.0],\n",
        "                    [2.0, 4.0, 2.0],\n",
        "                    [1.0, 2.0, 1.0], ])\n",
        "K /= 16.0\n",
        "\n",
        "def corr2d(X, K): \n",
        "    h, w = K.shape\n",
        "    Y = torch.zeros((X.shape[-2] - h + 1, X.shape[-1] - w + 1))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j] = (X[0][0][i:i + h, j:j + w] * K).sum() # producto de Haddamar\n",
        "    return Y\n",
        "\n",
        "Y = corr2d(X,K)\n",
        "\n",
        "# inserte su codigo.\n",
        "conv2d = nn.LazyConv2d(1, kernel_size=3, bias=False)\n",
        "\n",
        "lr = 3e-1  # Learning rate\n",
        "\n",
        "for i in range(100):\n",
        "    Y_hat = conv2d(X)\n",
        "    l = (Y_hat - Y) ** 2 ## minimos cuadrados\n",
        "    conv2d.zero_grad()\n",
        "    l.mean().backward()\n",
        "    # actualizamos los pesos\n",
        "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f'epoch {i + 1}, loss {l.sum():.3f}')\n",
        "\n",
        "print(conv2d.weight.data)\n",
        "print(K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6da2e04-c4c3-41ba-c6cd-8c9ed7f2efb6",
        "id": "86GJgyivs1_R"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20, loss 12.960\n",
            "epoch 40, loss 1.627\n",
            "epoch 60, loss 0.205\n",
            "epoch 80, loss 0.026\n",
            "epoch 100, loss 0.003\n",
            "tensor([[[[0.0628, 0.1258, 0.0610],\n",
            "          [0.1244, 0.2505, 0.1245],\n",
            "          [0.0647, 0.1242, 0.0622]]]])\n",
            "tensor([[0.0625, 0.1250, 0.0625],\n",
            "        [0.1250, 0.2500, 0.1250],\n",
            "        [0.0625, 0.1250, 0.0625]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Espacio de colores CMY"
      ],
      "metadata": {
        "id": "xD30BPxulPZH"
      }
    }
  ]
}